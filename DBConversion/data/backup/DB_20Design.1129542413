[[TableOfContents]]

= Questions =

== db connection ==
I think it might be faster/better to do the MySQLdb.connect() in the request object, once, and then just keep calling it...?  The DB connection could be a part of the request object?  Is there a downside to this?  (an instance where we need to use the DB but don't have a request object?)

''answer from #mysql: <firewire> codetoad, usually doesn't matter''

= Schema =
{{{Tables:

create table curPages
  (
  name varchar(255) primary key,
  text mediumtext,
  cachedText mediumblob,
  editTime datetime,
  cachedTime datetime,
  userEdited char(19)
  ) type=InnoDB;

alter table curPages add index userEdited(userEdited);

create table allPages
 (
    name varchar(255),
    text mediumtext,
    editTime datetime,
    userEdited char(19),
    editType enum('SAVE','SAVENEW','ATTNEW','ATTDEL','RENAME','NEWEVENT','COMMENT_MACRO','SAVE/REVERT'),
    comment varchar(81),
    userIP char(16),
    primary key(name, editTime)
  ) type=InnoDB;

alter table allPages add index userEdited(userEdited);
alter table allPages add index userIP(userIP);

create table users
(
id char(19) primary key,
name varchar(255),
email varchar(255),
enc_password varchar(255),
language varchar(80),
remember_me tinyint,
css_url varchar(255),
disabled tinyint,
edit_cols tinyint,
edit_rows tinyint,
edit_on_doubleclick tinyint,
theme_name char(40),
last_saved datetime,
join_date datetime,
created_count tinyint default 0,
edit_count tinyint default 0,
file_count tinyint default 0,
last_page_edited varchar(255),
last_edit_date datetime,
rc_bookmark datetime,
rc_showcomments tinyint default 1
) type=InnoDB;

alter table users add index name(name);

create table userFavorites
(
  username varchar(255),
  page varchar(255),
  viewTime datetime,
  primary key (username, page)
) type=InnoDB;

#This is throw-away data. User sessions aren't that important so we'll use a MyISAM table for speed
create table userSessions
(
  user_id char(19),
  session_id char(30),
  secret char(30),
  expire_time datetime,
  primary key (user_id, session_id)
) type=MyISAM;

alter table userSessions add index expire_time (expire_time);

#Links can be re-created if corrupt.  No need to worry about integrity so we'll use MyISAM for speed.
create table links
(
  source_pagename varchar(255),
  destination_pagename varchar(255),
  primary key (source_pagename, destination_pagename)
) type=MyISAM;

create table events
(
  uid mediumint primary key,
  event_time datetime,
  posted_by varchar(255) references users(name),
  text mediumtext,
  location mediumtext,
  event_name mediumtext,
  posted_by_ip char(16),
  posted_time datetime,
) type=InnoDB;

alter table events add index event_time (event_time);
alter table events add index posted_by_ip (posted_by_ip);
alter table events add index posted_time (posted_time);


create table images
(
   name varchar(255),
   image mediumblob,
   uploaded_time datetime,
   uploaded_by char(19),
   attached_to_pagename  varchar(255),
   uploaded_by_ip char(16),
   primary key (name, attached_to_pagename)
) type=InnoDB;

alter table images add index uploaded_by (uploaded_by);
alter table images add index uploaded_time (uploaded_time);

create table oldimages
(
  name varchar(255),
  image mediumblob,
  uploaded_time datetime,
  uploaded_by char(19),
  attached_to_pagename varchar(255),
  deleted_time datetime,
  deleted_by char(19),
  uploaded_by_ip char(16),
  deleted_by_ip char(16),
  primary key (name, attached_to_pagename, uploaded_time)
) type=InnoDB;

alter table oldimages add index deleted_time (deleted_time);

#throw-away and easily regenerated data
create table thumbnails
(              
  xsize tinyint,
  ysize tinyint,
  name varchar(255),
  attached_to_pagename varchar(255),
  image mediumblob,
  primary key (name, attached_to_pagename)
) type=MyISAM;

}}}

= To do =
== Basic working parts ==
 * --X Reading/writing of pages and backups. X--
 * --X Info, revisions, diffs, etc. X--
 * --X make sure pagedict is no where to be found in the code X--
 * --X ["Recent Changes"] X--
 * --X ["Bookmarks"] X--
 * --X ..then get rid of the logfile stuff -- search for it, kill it,X-- then kill the .py's
 * Misc functions

== The fun stuff ==
 * --X user table X-- and everything involved with removing the file-based user system
    * --X basics X--
    * --Xuser stats done via the user tableX--
    * --Xfavorites tableX--
  * --XCookies done via a table, as well.  Kill the damned seralized bullshit.X--
 * --Xlink tableX--

== Map issues ==
The new recent changes does not work off an editlog.  Instead, it uses a large SQL statement to get the changed pages, events, etc from the relevant tables.  This means that for map point changes to show up in the new recent changes we need the points.xml file to be instead table/s in the database.  Here is what I propose, schema-wise:

 * map_points:  (pagename varchar(255), x_location double, y_location double, edited_time datetime, edited_by char(19))
 * map_categories: (pagename varchar(255), cat_id tinyint, eidted_time datetime, edited_by char(19))
 * also, a possible old_points and old_categories similar to the other styles so that reverting or at least admin rollbacks would be easily possible.

How likely is it the map will be changing soon?  I can make it work like this but it'd require a bit of a hack:  I would need to make 'map.xml' a script that outputs the desired set of all points in XML format.. This isn't a very good solution, I don't think.  What's a good way to make this work?

== harder but also fun stuff ==
 * --Xevents boardX--
 * --XimagesX--
 * population script
 * full foreign key stuff in schema
[[Comments]]
